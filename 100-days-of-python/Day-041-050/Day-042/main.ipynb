{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLM5R8jLUKJr",
        "outputId": "6c751760-7083-4ec7-e7df-e18300e8b696"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
      ],
      "metadata": {
        "id": "-o5cOLtHUYUT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_input = [\n",
        "    {'question': 'what approach should I use?',\n",
        "     'context': 'Choose the approach that best suits your PyTorch version and coding style. Both options should correctly filter out the special tokens from the answer tokens.'}\n",
        "]"
      ],
      "metadata": {
        "id": "BJOJ-tI4U3fL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'deepset/roberta-base-squad2'"
      ],
      "metadata": {
        "id": "ttOEk7M2VL2e"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "oM8ctZTeVXcp"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs0 = tokenizer(qa_input[0]['question'], qa_input[0]['context'], return_tensors='pt')\n",
        "output = model(**inputs0)"
      ],
      "metadata": {
        "id": "iH731busVyHq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YukYsQlJWiBy",
        "outputId": "ee2a59f3-0193-4b60-81d4-081288c9c0e4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 1.0495, -7.3381, -8.5000, -7.8661, -8.1849, -8.5136, -9.2261, -9.2812,\n",
              "         -7.5867,  0.7729,  0.7222, -0.2984, -0.7297,  0.0865, -3.4161, -0.9853,\n",
              "          1.2590, -5.3333, -5.5722, -4.0485, -5.7790, -0.5781, -4.2728, -4.8642,\n",
              "         -0.4021, -2.0183, -2.3202, -0.6149, -0.2125, -5.5084, -4.8359, -1.6971,\n",
              "         -3.4317, -5.6870, -4.0073, -2.2249, -4.0954, -4.8643, -8.6626]],\n",
              "       grad_fn=<CloneBackward0>), end_logits=tensor([[ 1.5199, -7.0387, -6.6101, -7.4649, -7.8680, -7.2983, -6.5304, -7.3271,\n",
              "         -6.2690, -3.3692, -4.1292, -0.9853, -4.3091, -3.5078, -2.0591, -4.0430,\n",
              "         -4.7428, -3.8972,  1.0064,  1.8883, -4.3184,  0.3253,  2.8870,  0.9605,\n",
              "         -3.2935, -0.9885, -5.5404, -3.9270, -3.3515, -3.7936, -6.7907, -4.5560,\n",
              "          0.4229, -6.2407, -6.7304, -3.6935,  1.6809,  0.9605, -6.7025]],\n",
              "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_start_idx = torch.argmax(output.start_logits)\n",
        "answer_end_idx = torch.argmax(output.end_logits)\n",
        "\n",
        "answer_tokens = inputs0.input_ids[0, answer_start_idx:answer_end_idx+1]\n",
        "answer = tokenizer.decode(answer_tokens)"
      ],
      "metadata": {
        "id": "axGZDd4jXI6i"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Question: \\nand Answer is {}\".format(answer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUchp29DYFLF",
        "outputId": "6f74a460-582b-4eb6-b31b-7dd50e157d34"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: \n",
            "and Answer is  PyTorch version and coding style\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_input = [\n",
        "  {'question': 'What is speciality of Laravel?',\n",
        "   'context': 'Laravel is a web application framework with expressive, elegant syntax. A web framework provides a structure and starting point for creating your application, allowing you to focus on creating something amazing while we sweat the details.'\n",
        "   }\n",
        "]\n",
        "\n",
        "inputs0 = tokenizer(qa_input[0]['question'], qa_input[0]['context'], return_tensors='pt')\n",
        "output = model(**inputs0)\n",
        "\n",
        "# Filter special tokens using their corresponding token IDs\n",
        "answer_start_idx = torch.argmax(output.start_logits)\n",
        "answer_end_idx = torch.argmax(output.end_logits)\n",
        "\n",
        "special_tokens_ids = tokenizer.convert_tokens_to_ids(tokenizer.special_tokens_map)\n",
        "answer_tokens = inputs0.input_ids[0, answer_start_idx:answer_end_idx+1]\n",
        "\n",
        "filtered_tokens = []\n",
        "for token in answer_tokens:\n",
        "    if token not in special_tokens_ids:\n",
        "        filtered_tokens.append(token)\n",
        "answer_tokens = torch.tensor(filtered_tokens)\n",
        "\n",
        "\n",
        "answer = tokenizer.decode(answer_tokens)\n",
        "\n",
        "print(\"Question: {} \\nAnswer: {}\".format(qa_input[0]['question'], answer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5JwnPYZZGrb",
        "outputId": "f7f1d4b5-e183-466d-9e3a-9b10c56271f7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is speciality of Laravel? \n",
            "Answer:  expressive, elegant syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgYsipXJZ8r7",
        "outputId": "556b7fe7-6e5d-41bc-88ef-c4ffecf76afb"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([19972, 30562,   611,  1732,     8, 25776,  2496])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}